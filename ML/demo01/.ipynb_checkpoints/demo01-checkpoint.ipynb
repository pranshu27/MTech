{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import time as t\n",
    "\n",
    "# cs771 will be our course package and will contain several modules\n",
    "# Right now we have a dummy module, a data generation module and a data plotting module\n",
    "from cs771 import helloWorld as hW\n",
    "from cs771 import genSyntheticData as gsd\n",
    "from cs771 import plotData as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will work with a toy dataset in 2D with 20 points per class\n",
    "# Feel free to change n and see what happens. Changing d will break things though\n",
    "d = 2 \n",
    "n = 20\n",
    "\n",
    "# Choose points around which positive and negative class points will be sampled\n",
    "muPos = np.array( [-5,5] )\n",
    "muNeg = np.array( [5,0] )\n",
    "\n",
    "# Generate nice spherical data using our data generation module\n",
    "# Choose a nice radius\n",
    "r = 3\n",
    "XPos = gsd.genSphericalData( d, n, muPos, r )\n",
    "XNeg = gsd.genSphericalData( d, n, muNeg, r )\n",
    "\n",
    "# Let us plot these points on a plane and see where they landed\n",
    "# First, obtain a new figure from the plotting module - the two arguments set the size of the figure\n",
    "fig1 = pd.getFigure( 7, 7 )\n",
    "\n",
    "# The three commands below are just to give the plot an aesthetic aspect ratio - do not worry about this\n",
    "ax = fig1.add_axes( [0,0,0.75,0.75] )\n",
    "ax.set_xlim( [-10, 10] )\n",
    "ax.set_ylim( [-10, 10] )\n",
    "\n",
    "# Now, plot the sampled points - you can change the color, marker and size of the markers\n",
    "pd.plot2D( XPos, fig1, color = 'r', marker = '+' )\n",
    "pd.plot2D( XNeg, fig1, color = 'g', marker = 'o' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate prototypes for the two classes\n",
    "protoPos = np.sum( XPos, 0 )/n\n",
    "protoNeg = np.sum( XNeg, 0 )/n\n",
    "\n",
    "# Define the Learning with Prototypes classifer\n",
    "# This takes in just one 2D data point (x, y are scalars) and tells us which prototype was closer\n",
    "def LwP( x, y ):\n",
    "    return lin.norm( np.array( [x,y] ) - protoPos, 2 ) - lin.norm( np.array( [x,y] ) - protoNeg, 2 )\n",
    "\n",
    "# Let us see what this classifier does i.e. where is its decision boundary\n",
    "# Get another figure\n",
    "fig2 = pd.getFigure( 7, 7 )\n",
    "\n",
    "# Use the plotting module to shade the entire 2D space and visualize the decision boundary\n",
    "tic = t.process_time()\n",
    "pd.shade2D( LwP, fig2, mode = 'point', xlim = 10, ylim = 10 )\n",
    "toc = t.process_time()\n",
    "print( \"It took \" + str(toc - tic) + \" seconds to complete the shading \")\n",
    "pd.plot2D( XPos, fig2, color = 'r', marker = '+' )\n",
    "pd.plot2D( XNeg, fig2, color = 'g', marker = 'o' )\n",
    "\n",
    "# Plot the prototype locations as well to see where they lie w.r.t the decision boundary\n",
    "pd.plot2DPoint( protoPos, fig2, color = 'm', marker = '*' )\n",
    "pd.plot2DPoint( protoNeg, fig2, color = 'k', marker = 's' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us develop a (much) faster version of the LwP classifier. This takes in an entire matrix of data points\n",
    "# and uses broadcasting to find the LwP decision on them all at once. In Python and other scripting languages\n",
    "# processing data in batches is much faster than running a for loop that processes data one by one.\n",
    "def LwPBatch( X ):\n",
    "    return lin.norm( X - protoPos, ord = 2, axis = 1 ) - lin.norm( X - protoNeg, ord = 2, axis = 1 )\n",
    "\n",
    "fig3 = pd.getFigure( 7, 7 )\n",
    "\n",
    "# Use the batch mode now - try running both point and batch mode to see that this version is 20-30 times faster \n",
    "tic = t.process_time()\n",
    "pd.shade2D( LwPBatch, fig3, mode = 'batch', xlim = 10, ylim = 10 )\n",
    "toc = t.process_time()\n",
    "print( \"It took \" + str(toc - tic) + \" seconds to complete the shading \")\n",
    "pd.plot2D( XPos, fig3, color = 'r', marker = '+' )\n",
    "pd.plot2D( XNeg, fig3, color = 'g', marker = 'o' )\n",
    "pd.plot2DPoint( protoPos, fig3, color = 'm', marker = '*' )\n",
    "pd.plot2DPoint( protoNeg, fig3, color = 'k', marker = 's' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us now generate data where LwP will fail\n",
    "muPos = np.array( [-3,0] )\n",
    "muNeg = np.array( [3,3] )\n",
    "cov = np.array( [[16, -14] , [-14, 16]] )\n",
    "\n",
    "XPos = gsd.genEllipticalData( d, n, muPos, cov )\n",
    "XNeg = gsd.genEllipticalData( d, n, muNeg, cov )\n",
    "\n",
    "# Since we have new data, we need to recalculate prototypes for the two classes\n",
    "protoPos = np.sum( XPos, 0 )/n\n",
    "protoNeg = np.sum( XNeg, 0 )/n\n",
    "\n",
    "fig4 = pd.getFigure( 7, 7 )\n",
    "pd.shade2D( LwPBatch, fig4, mode = 'batch', xlim = 10, ylim = 10 )\n",
    "pd.plot2D( XPos, fig4, color = 'r', marker = '+' )\n",
    "pd.plot2D( XNeg, fig4, color = 'g', marker = 'o' )\n",
    "pd.plot2DPoint( protoPos, fig4, color = 'm', marker = '*' )\n",
    "pd.plot2DPoint( protoNeg, fig4, color = 'k', marker = 's' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now use a weighted Euclidean distance to fix this problem\n",
    "W = np.array( [[1/4, 1/4], [1/4, 1]] )\n",
    "L = lin.cholesky( W )\n",
    "\n",
    "# Recall that the weighted Euclidean distance is simply the Euclidean distance between vectors\n",
    "# transformed using L where A = LL'\n",
    "def LwPWeightedEuclideanBatch ( X ):\n",
    "    return lin.norm( np.matmul( X - protoPos, L), ord = 2, axis = 1 ) - lin.norm( np.matmul( X - protoNeg, L), ord = 2, axis = 1 )\n",
    "\n",
    "fig5 = pd.getFigure( 7, 7 )\n",
    "pd.shade2D( LwPWeightedEuclideanBatch, fig5, mode = 'batch', xlim = 10, ylim = 10 )\n",
    "pd.plot2D( XPos, fig5, color = 'r', marker = '+' )\n",
    "pd.plot2D( XNeg, fig5, color = 'g', marker = 'o' )\n",
    "pd.plot2DPoint( protoPos, fig5, color = 'm', marker = '*' )\n",
    "pd.plot2DPoint( protoNeg, fig5, color = 'k', marker = 's' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LwPMahlanobisBatch ( X ):\n",
    "    return lin.norm( np.matmul( X - protoPos, L), ord = 2, axis = 1 ) - lin.norm( np.matmul( X - protoNeg, L), ord = 2, axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now use a Mahalanobis distance to fix the problem without having to specify a weight matrix\n",
    "X = np.array(list(XPos) + list(XNeg))\n",
    "B = np.linalg.inv(np.cov(X, rowvar=False))\n",
    "L = lin.cholesky( B )\n",
    "\n",
    "# Recall that the Mahalanobis distance w.r.t. matrix A is merely the Euclidean distance between vectors\n",
    "# transformed using L where A = LL'\n",
    "def LwPMahlanobisBatch ( X ):\n",
    "    return lin.norm( np.matmul( X - protoPos, L), ord = 2, axis = 1 ) - lin.norm( np.matmul( X - protoNeg, L), ord = 2, axis = 1 )\n",
    "\n",
    "fig5 = pd.getFigure( 7, 7 )\n",
    "pd.shade2D( LwPMahlanobisBatch, fig5, mode = 'batch', xlim = 10, ylim = 10 )\n",
    "pd.plot2D( XPos, fig5, color = 'r', marker = '+' )\n",
    "pd.plot2D( XNeg, fig5, color = 'g', marker = 'o' )\n",
    "pd.plot2DPoint( protoPos, fig5, color = 'm', marker = '*' )\n",
    "pd.plot2DPoint( protoNeg, fig5, color = 'k', marker = 's' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take home problem\n",
    "\n",
    "1. Implement a kNN classifier to solve this same problem. \n",
    "2. Change the data such that kNN starts to have trouble classifying correctly\n",
    "3. Find the best k for kNN for such data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": {
   "email": "purushot@cse.iitk.ac.in",
   "institution": "IIT Kanpur",
   "name": "Puru"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
